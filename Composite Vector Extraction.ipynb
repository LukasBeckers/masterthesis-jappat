{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79653131-32a4-4a16-9f9f-8aebe00345d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Own Packages\n",
    "from Masterarbeit_utils.model_utils import get_tokenizer, load_and_modify_model, load_pretrained_Tokenizer\n",
    "\n",
    "# Site-Packages\n",
    "import dask.dataframe as dd\n",
    "import torch\n",
    "import psutil\n",
    "import os\n",
    "import sys\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bokeh\n",
    "\n",
    "# Dimension reduction algorithms\n",
    "from cuml.manifold import TSNE as cuml_tsne\n",
    "from sklearn.manifold import TSNE\n",
    "# Bokeh\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.io import export_png\n",
    "\n",
    "from transformers import AutoTokenizer, OPTForCausalLM\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "%matplotlib inline\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21476781-1315-4c47-aea1-d31f57e5dc2b",
   "metadata": {},
   "source": [
    "# Loading the Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0668b9b6-92f0-4f6d-9be2-6bd56535ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "#Parameters\n",
    "############\n",
    "\n",
    "\"\"\"\n",
    "The Paths to important folders have to be changed for your system.\n",
    "\"\"\"\n",
    "\n",
    "# Name of this experiment\n",
    "model_name = 'gal_125_1'\n",
    "\n",
    "checkpoint = 140000\n",
    "\n",
    "# This folder will be created and filled with txt.files for each sample after you run the Pytorch Dataset Notebook\n",
    "dataset_folder = f'data/dataset_samples'\n",
    "\n",
    "# The folder at which the model will be saved. This folder has to be created for your system \n",
    "model_folder = f'data/models/{model_name}'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# Folder in which the tokenizer will be saved\n",
    "tokenizer_folder = f'data/tokenizers/{model_name}'\n",
    "os.makedirs(tokenizer_folder, exist_ok=True)\n",
    "\n",
    "# Folder at which all pickle files are stored. This folder is fixed for this project and should not be changed\n",
    "dump_dir = r'PK_DUMP'\n",
    "\n",
    "# Model parameters \n",
    "'''\n",
    "mini\t125 M\n",
    "base\t1.3 B\n",
    "standard\t6.7 B\n",
    "large\t30 B\n",
    "huge\t120 B'''\n",
    "base_model_name = 'mini'\n",
    "\n",
    "# All new Torch-objects will be by default in this dtype\n",
    "# if default_type = float16 fp16 must be False\n",
    "default_dtype = torch.float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_default_dtype(default_dtype)\n",
    "\n",
    "# Default device on which the model will be loaded\n",
    "default_device = 'cpu'\n",
    "\n",
    "# Number of GPUs the model will be parallelised to \n",
    "num_gpus = 1\n",
    "# If you change 'default_device' to 'cpu', make sure to set num_gpus to zero.\n",
    "if default_device == 'cpu':\n",
    "    num_gpus = 0\n",
    "\n",
    "tensor_parallel = False\n",
    "\n",
    "\n",
    "\n",
    "###########################\n",
    "# Loading the Model\n",
    "###########################\n",
    "device_map=None\n",
    "max_memory = {}\n",
    "if num_gpus > 0:\n",
    "    # based on https://github.com/huggingface/accelerate/blob/5315290b55ea9babd95a281a27c51d87b89d7c85/src/accelerate/utils/modeling.py#L274\n",
    "    for i in range(num_gpus):\n",
    "        _ = torch.tensor([0], device=i)\n",
    "    for i in range(num_gpus):\n",
    "        max_memory[i] = torch.cuda.mem_get_info(i)[0]\n",
    "    device_map = \"auto\"\n",
    "max_memory[\"cpu\"] = psutil.virtual_memory().available\n",
    "             \n",
    "model = OPTForCausalLM.from_pretrained(f'{model_folder}/checkpoint-{checkpoint}', torch_dtype=default_dtype, low_cpu_mem_usage=True,\n",
    "                                               device_map=device_map, max_memory=max_memory)\n",
    "\n",
    "###########################\n",
    "# Loading the Tokenizer\n",
    "###########################\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_folder)\n",
    "n_f_terms = len(tokenizer) - tokenizer.vocab_size\n",
    "print('Loadede Tokenizer from serialized instance!')    \n",
    "print(f'There are {n_f_terms} different F-Terms in the whole Dataset!')\n",
    "\n",
    "\n",
    "###########################\n",
    "# Loading Descriptions\n",
    "###########################\n",
    "with open(f'{dump_dir}/themes_descriptions.pk', 'rb') as f:\n",
    "    theme_dict = pk.load(f)\n",
    "with open(f'{dump_dir}/viewpoints_descriptions.pk', 'rb') as f:\n",
    "    viewpoint_dict = pk.load(f)\n",
    "with open(f'{dump_dir}/numbers_descriptions.pk', 'rb') as f:\n",
    "    number_dict = pk.load(f)\n",
    "with open(f'{dump_dir}/full_descriptions.pk', 'rb') as f:\n",
    "        full_descriptions_dict = pk.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0127ad91-ff1f-4f9d-a65c-13e1a8554895",
   "metadata": {},
   "source": [
    "# Extracting the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd91286-6b8e-4ac9-a7e4-1d89710973b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = model.get_input_embeddings()\n",
    "emb = emb(torch.arange(len(tokenizer))).detach().numpy()\n",
    "\n",
    "out_emb = model.get_output_embeddings()\n",
    "out_emb = next(out_emb.parameters()).detach().numpy()\n",
    "\n",
    "print(emb.shape, out_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b4d85-823c-41d1-bac1-07e702b4e382",
   "metadata": {},
   "source": [
    "# Sorting the F-Terms by Theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142123ae-fbc9-4d10-b5bd-368259db5033",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = [tokenizer.decode(i) for i in range(len(tokenizer))]\n",
    "f_terms = all_tokens[50001:]\n",
    "\n",
    "# Generating Theme Clusters\n",
    "theme_clusters = {}\n",
    "\n",
    "for emb_vector, f_term in zip(out_emb[1:], f_terms):\n",
    "    theme = f_term.split('/')[0]\n",
    "    try:\n",
    "        _ = theme_clusters[theme]\n",
    "        theme_clusters[theme].append(emb_vector)\n",
    "\n",
    "    except KeyError:\n",
    "        theme_clusters[theme] = [emb_vector]\n",
    "\n",
    "print(f'Number of Themes:{len(theme_clusters)}')\n",
    "        \n",
    "# Averaging the Vectors to generate the vectors corrisponding to the overarching Theme\n",
    "mean_theme_vectors = {}\n",
    "\n",
    "for theme, vectors in theme_clusters.items():\n",
    "    mean_theme_vectors[theme] = np.mean(vectors, axis=-2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb7c992-5c7c-4aed-86b2-23ee8359b60d",
   "metadata": {},
   "source": [
    "# Plotting the Theme Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93644ea1-52b1-47df-831b-c8e3fdb93467",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [vector for vector in mean_theme_vectors.values()]\n",
    "vectors = np.stack(vectors, axis=0)\n",
    "\n",
    "themes = [key for key in mean_theme_vectors.keys()]\n",
    "\n",
    "\n",
    "\n",
    "# Calculating a TSNE Representation\n",
    "print('Calculating T-SNE Representation')\n",
    "tsne = TSNE(n_components=2, verbose=0, random_state=69) \n",
    "tsne_rep = tsne.fit_transform(vectors)\n",
    "\n",
    "# Plotting the Themes\n",
    "print('Plotting')\n",
    "datasource_themes = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x = tsne_rep[:,0],\n",
    "            y = tsne_rep[:,1],\n",
    "            themes = themes, \n",
    "            descriptions = [theme_dict[theme] for theme in themes]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "hover_tsne = HoverTool(tooltips='<div style=\"font-size: 12px;\"><b>Theme:</b> @themes<br><b>Description:</b> @descriptions</div>', mode='mouse')\n",
    "tools_tsne = [hover_tsne, 'pan', 'wheel_zoom', 'reset']\n",
    "plot_tsne = figure(width=1500, height=1500, tools=tools_tsne, title='Theme Vectors')\n",
    "    \n",
    "    \n",
    "plot_tsne.square('x', 'y', size=5, fill_color='blue', \n",
    "                     alpha=0.7, line_width=0, source=datasource_themes, name=\"F-Terms\")\n",
    "\n",
    "show(plot_tsne)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b93270d-7874-4802-bae8-fbf213bd7230",
   "metadata": {},
   "source": [
    "# Plotting F-Term vectors without Theme Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a883a12-14f3-474d-80b4-c65b5084b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting the theme Vector from the F-Terms\n",
    "out_emb_no_theme = []\n",
    "themes = []\n",
    "\n",
    "for i, x in enumerate(zip(out_emb[1:], f_terms)):\n",
    "    emb_vector, f_term = x\n",
    "    theme = f_term.split('/')[0]\n",
    "    themes.append(theme)\n",
    "    emb_vector -= mean_theme_vectors[theme]\n",
    "    out_emb_no_theme.append(emb_vector)\n",
    "\n",
    "out_emb_no_theme = np.stack(out_emb_no_theme, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339159db-8dfc-4263-bbec-2d07dd749b07",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Calculating the T-SNE Representation\n",
    "print('Calculating T-SNE Representation')\n",
    "tsne = TSNE(n_components=2, verbose=0, random_state=69) \n",
    "tsne_rep = tsne.fit_transform(out_emb_no_theme)\n",
    "# The calculation takes really long for this reason the plotting is done in the next cell for rapid changes to the plot without recalculating the T-SNE representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc7692-f3b1-4a4c-954b-1c1dd6f250f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{model_folder}/No Theme F-Term Emb TSNE.pk', 'rb') as f:\n",
    "    tsne_rep= pk.load(f)\n",
    "\n",
    "tsne_rep.shape, tsne_rep[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99047a94-e647-4524-b38d-808cc1a7ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color Palette to make the plot prettier\n",
    "bokeh_palette = bokeh.palettes.Turbo256\n",
    "color_palette = bokeh_palette\n",
    "color_theme_dict = {theme: color_palette[i%256] for i, theme in enumerate(set(themes))}\n",
    "\n",
    "print(len(themes))\n",
    "colors = [color_theme_dict[theme] for theme in themes]\n",
    "\n",
    "x = -1\n",
    "# Plotting the Themes\n",
    "print('Plotting', colors[:2], themes[:2], len(colors))\n",
    "datasource_themes = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x = tsne_rep[:x,0],\n",
    "            y = tsne_rep[:x,1],\n",
    "            themes = themes[:x], \n",
    "            colors = colors[:x], \n",
    "            descriptions = [full_descriptions_dict[f_term[:-1]] for f_term in f_terms][:x]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "hover_tsne = HoverTool(tooltips='<div style=\"font-size: 12px;\"><b>Theme:</b> @themes<br><b>Description:</b> @descriptions</div>', mode='mouse')\n",
    "tools_tsne = [hover_tsne, 'pan', 'wheel_zoom', 'reset']\n",
    "plot_tsne = figure(width=1500, height=1500, tools=tools_tsne, title='F Terms with no Theme Vectors')\n",
    "    \n",
    "    \n",
    "plot_tsne.square('x', 'y', size=5, fill_color='colors', \n",
    "                     alpha=0.7, line_width=0, source=datasource_themes, name=\"F-Terms\")\n",
    "\n",
    "show(plot_tsne)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ecba4e-9229-45c0-9584-495e39e6fee3",
   "metadata": {},
   "source": [
    "with open(f'{model_folder}/No Theme F-Term Emb TSNE.pk', 'wb') as f:\n",
    "    pk.dump(tsne_rep, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7170dc36-78f4-4d4e-8697-0295edbec49b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
