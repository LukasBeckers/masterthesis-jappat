{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54e5a328-7461-4e78-8862-96de705dcbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worker/.pyenv/versions/3.10.0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('3.10.0 (default, Jul 12 2023, 08:49:30) [GCC 12.2.0]',\n",
       " '/home/worker/.pyenv/versions/3.10.0/bin/python3.10')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Own Packages\n",
    "from Masterarbeit_utils.model_utils import get_tokenizer, load_and_modify_model, load_pretrained_Tokenizer\n",
    "\n",
    "# Site-Packages\n",
    "import dask.dataframe as dd\n",
    "import torch\n",
    "import psutil\n",
    "import os\n",
    "import sys\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, OPTForCausalLM\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from torch.utils.data import Dataset\n",
    "sys.version, sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e8bd44-8e8c-41f8-8086-8f093520c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Paths to important folders have to be changed for your system.\n",
    "\"\"\"\n",
    "\n",
    "# This folder will be created and filled with txt.files for each sample after you run the Pytorch Dataset Notebook\n",
    "dataset_folder = f'data/dataset_samples'\n",
    "\n",
    "# The folder at which the model will be saved. This folder has to be created for your system \n",
    "model_folder = f'data/models/gal_125_1'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# The folder at which the training progress will be logged\n",
    "log_folder = f'data/models/gal_125_1/logs'\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "# Folder at which all pickle files are stored. This folder is fixed for this project and should not be changed\n",
    "dump_dir = r'PK_DUMP'\n",
    "\n",
    "# Model parameters \n",
    "'''\n",
    "mini\t125 M\n",
    "base\t1.3 B\n",
    "standard\t6.7 B\n",
    "large\t30 B\n",
    "huge\t120 B'''\n",
    "base_model_name = 'mini'\n",
    "\n",
    "# All new Torch-objects will be by default in this dtype\n",
    "# if default_type = float16 fp16 must be False\n",
    "default_dtype = torch.bfloat16\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_default_dtype(default_dtype)\n",
    "\n",
    "# Default device on which the model will be loaded\n",
    "default_device = 'cuda:0'\n",
    "\n",
    "# Number of GPUs the model will be parallelised to \n",
    "num_gpus = 1\n",
    "# If you change 'default_device' to 'cpu', make sure to set num_gpus to zero.\n",
    "if default_device == 'cpu':\n",
    "    num_gpus = 0\n",
    "\n",
    "tensor_parallel = False\n",
    "n_f_terms = None # Will be calculated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b06129-7179-43e2-8e3c-e8d8c2543571",
   "metadata": {},
   "source": [
    "# Creating the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd265196-d3eb-4e46-be5a-97860017c369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 378164 different F-Terms in the whole Dataset!\n"
     ]
    }
   ],
   "source": [
    "# Loads a pretrained Tokenizer for the galactica model and adds an additional token for each F-Term\n",
    "tokenizer = get_tokenizer(dump_dir)\n",
    "\n",
    "# The Tokenizer contained initially 50000 Tokens which are stored as the vocab-size.\n",
    "# The vocab_size attribute is not updated when the additional tokens are added to the tokenizer\n",
    "n_f_terms = len(tokenizer) - tokenizer.vocab_size\n",
    "print(f'There are {n_f_terms} different F-Terms in the whole Dataset!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e3dfa-af05-4a7a-a86b-35db53103afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24daf4c-70b0-4497-b22c-971bd8c75dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43873f-570a-4ecd-b4ce-117b4e24e0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a2b13-d64d-4c5f-bc1e-b03539e853ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
